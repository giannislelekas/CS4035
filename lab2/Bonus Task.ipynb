{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task  Not completed \n",
    "- LSTM implementation for anomaly detction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model, Sequential \n",
    "from keras.layers import Input, Dense, Dropout,LSTM, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       L_T1      L_T2      L_T3      L_T4      L_T5      L_T6      L_T7  \\\n",
      "0  0.509730  2.049003  3.191145  2.792634  2.656091  5.316831  1.562321   \n",
      "1  0.412580  2.009072  3.642565  2.831673  3.126387  5.494855  1.852043   \n",
      "2  0.320112  1.986093  4.140192  3.256733  3.574601  5.500000  2.246126   \n",
      "3  0.332879  2.009203  4.673478  3.744497  3.952379  5.500000  3.203573   \n",
      "4  0.483496  2.089049  5.237937  4.409456  3.504676  5.500000  4.439714   \n",
      "\n",
      "       F_PU1  S_PU1      F_PU2  ...     P_J256     P_J289     P_J415  \\\n",
      "0  98.998444    1.0  99.018150  ...  87.605774  26.495605  84.206619   \n",
      "1  99.095901    1.0  99.115639  ...  89.448341  26.487326  85.900085   \n",
      "2  98.420959    1.0  98.440498  ...  91.056114  26.487364  86.582474   \n",
      "3  97.575172    1.0  97.594460  ...  92.594353  26.575815  88.020546   \n",
      "4  97.351059    1.0  97.370277  ...  94.473099  26.723457  90.422462   \n",
      "\n",
      "      P_J302     P_J306     P_J307     P_J317      P_J14     P_J422  ATT_FLAG  \n",
      "0  18.901676  81.983734  18.791777  67.125603  29.387470  28.487471         0  \n",
      "1  18.849329  82.150589  18.739643  67.178696  29.354256  28.454256         0  \n",
      "2  19.597170  83.988579  19.496712  72.425293  29.354538  28.454538         0  \n",
      "3  26.028486  64.670486  25.922703  76.275040  29.449951  28.549952         0  \n",
      "4  26.209970  64.746620  26.104692  76.703529  29.574265  28.674263         0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "(4177, 44)\n",
      "(8761, 44)\n",
      "(12938, 44)\n"
     ]
    }
   ],
   "source": [
    "SEED = 123 \n",
    "DATA_SPLIT_PCT = 0.2\n",
    "\n",
    "LABELS = [\"Normal\",\"Attack\"]\n",
    "\n",
    "# please adjust the dataset paths\n",
    "NORMAL = \"./data/BATADAL_dataset03.csv\"\n",
    "MIXED = \"./data/BATADAL_dataset04.csv\"\n",
    "\n",
    "df_normal =  pd.read_csv(NORMAL, skipinitialspace=True)\n",
    "df_mixed = pd.read_csv(MIXED, skipinitialspace=True)\n",
    "df_mixed.ATT_FLAG.replace([-999, 1], [0, 1], inplace=True)\n",
    "df_normal = df_normal.drop(['DATETIME'], axis=1)\n",
    "df_mixed = df_mixed.drop(['DATETIME'], axis=1)\n",
    "\n",
    "df = pd.concat([df_normal, df_mixed], ignore_index=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df_mixed.shape)\n",
    "print(df_normal.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12938, 44)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_df = scaler.fit_transform(values)\n",
    "print(scaled_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8280, 44)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
    "\n",
    "\n",
    "df_train_0 = df_train.loc[df['ATT_FLAG'] == 0]\n",
    "df_train_1 = df_train.loc[df['ATT_FLAG'] == 1]\n",
    "df_train_test = df_train_0['ATT_FLAG']\n",
    "df_train_0_x = df_train_0.drop(['ATT_FLAG'], axis=1)\n",
    "df_train_1_x = df_train_1.drop(['ATT_FLAG'], axis=1)\n",
    "\n",
    "\n",
    "df_valid_0 = df_valid.loc[df['ATT_FLAG'] == 0]\n",
    "df_valid_1 = df_valid.loc[df['ATT_FLAG'] == 1]\n",
    "\n",
    "df_valid_0_x = df_valid_0.drop(['ATT_FLAG'], axis=1)\n",
    "df_valid_1_x = df_valid_1.drop(['ATT_FLAG'], axis=1)\n",
    "df_valid_test = df_valid_0['ATT_FLAG']\n",
    "\n",
    "\n",
    "df_test_0 = df_test.loc[df['ATT_FLAG'] == 0]\n",
    "df_test_1 = df_test.loc[df['ATT_FLAG'] == 1]\n",
    "\n",
    "df_test_0_x = df_test_0.drop(['ATT_FLAG'], axis=1)\n",
    "df_test_1_x = df_test_1.drop(['ATT_FLAG'], axis=1)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2588, 43)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(df_train_0_x)\n",
    "df_train_0_x_rescaled = scaler.transform(df_train_0_x)\n",
    "df_valid_0_x_rescaled = scaler.transform(df_valid_0_x)\n",
    "df_valid_x_rescaled = scaler.transform(df_valid.drop(['ATT_FLAG'], axis = 1))\n",
    "\n",
    "df_test_0_x_rescaled = scaler.transform(df_test_0_x)\n",
    "df_test_x_rescaled = scaler.transform(df_test.drop(['ATT_FLAG'], axis = 1))\n",
    "df_test_x_rescaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8143, 1, 43)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train =df_train_0_x_rescaled.reshape(( df_train_0_x_rescaled.shape[0],1,df_train_0_x_rescaled.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "y_train = df_valid_0_x_rescaled.reshape(( df_valid_0_x_rescaled.shape[0],1,df_valid_0_x_rescaled.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-train data shape(batch_size,timesteps,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 1, 50)             18800     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 39,051\n",
      "Trainable params: 39,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape= (1,x_train.shape[2]),activation='relu', return_sequences= True))\n",
    "model.add(LSTM(50))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation= 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer ='adam', metrics= ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8143 samples, validate on 2030 samples\n",
      "Epoch 1/70\n",
      " - 2s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 2/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 3/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 4/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 5/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 6/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 7/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 8/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 9/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 10/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 11/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 12/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 13/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 14/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 15/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 16/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 17/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 18/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 19/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 20/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 21/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 22/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 23/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 24/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 25/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 26/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 27/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 28/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 29/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 30/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 31/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 32/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 33/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 34/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 35/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 36/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 37/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 38/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 39/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 40/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 41/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 42/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 43/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 44/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 45/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 46/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 47/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 48/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 49/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 50/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 51/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 52/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 53/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 54/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 55/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 56/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 57/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 58/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 59/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 60/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 61/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 62/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 63/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 64/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 65/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 66/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 67/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 68/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 69/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n",
      "Epoch 70/70\n",
      " - 0s - loss: 1.0000 - acc: 0.0000e+00 - val_loss: 1.0000 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history =  model.fit(x_train, df_train_test, epochs =70 , batch_size = 128, validation_data = (y_train, df_valid_test), verbose =2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49114364e+00 1.07358920e-01 6.19574012e+00 ... 6.11162100e+00\n",
      "  5.53404197e+00 7.07867190e+00]\n",
      " [1.07999476e+00 2.41002538e-02 6.12288254e+00 ... 6.11162100e+00\n",
      "  5.53404197e+00 6.33098442e+00]\n",
      " [4.45113181e-01 5.57955534e-01 3.23725221e+00 ... 6.11162100e+00\n",
      "  5.53404197e+00 5.62501849e+00]\n",
      " ...\n",
      " [2.75336890e+00 1.84712578e+00 8.07359660e+00 ... 3.00079274e-01\n",
      "  3.35420395e-04 2.67227014e-01]\n",
      " [3.92745111e+00 2.31746918e+00 5.21494713e+00 ... 3.00079274e-01\n",
      "  3.35420395e-04 4.37413793e-01]\n",
      " [5.42440738e+00 3.21979794e+00 2.87806921e+00 ... 3.00079274e-01\n",
      "  9.68108653e-03 7.07867190e+00]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_new )\n",
    "mse = np.mean(np.power(test_new - pred, 2), axis=1)\n",
    "\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
